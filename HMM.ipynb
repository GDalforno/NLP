{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Avaliação do Hidden Markov Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "import os\n",
    "import random\n",
    "import functools\n",
    "import collections\n",
    "import nltk\n",
    "import numpy as np\n",
    "from nltk.tag.hmm import HiddenMarkovModelTrainer\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "random.seed(1999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DIR = \"./dados-categorias/PLs/\"  \n",
    "# DIR = \"./dados-tipos/PLs/\"  \n",
    "# DIR = \"./dados-categorias/STs/\"\n",
    "# DIR = \"./dados-tipos/STs/\"\n",
    "# DIR = \"./dados-categorias/Comentarios/\"\n",
    "DIR = \"./dados-tipos/Comentarios/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = [DIR+f for f in os.listdir(DIR)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_conll_file(location:str)->list:\n",
    "    with open(location, \"r\") as f:\n",
    "        data = f.read()\n",
    "    data = data.split(\"\\n\\n\")\n",
    "    data = list(map(lambda x:x.split(\"\\n\"), data))\n",
    "    data.pop()\n",
    "    data = list(map(lambda x:[operator.itemgetter(*[0, -1])(y.split(\" \")) for y in x], data))\n",
    "    return data\n",
    "\n",
    "def combine_files(locations:list)->list:\n",
    "    extended = []\n",
    "    for f in locations:\n",
    "        extended.extend(process_conll_file(f))\n",
    "    return extended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de Sentenças no Conjunto de Treinamento: 725\n",
      "Número de Sentenças no Conjunto de Teste: 242\n"
     ]
    }
   ],
   "source": [
    "# Divisão entre Conjuntos de Treinamento e de Teste\n",
    "if DIR==\"./dados-categorias/PLs/\" or DIR==\"./dados-tipos/PLs/\":\n",
    "    train_size = int(0.75*len(all_files))\n",
    "    random.shuffle(all_files)\n",
    "    train_files = all_files[:train_size]\n",
    "    test_files = all_files[train_size:]\n",
    "    \n",
    "    train = combine_files(train_files)\n",
    "    test = combine_files(test_files)\n",
    "else:\n",
    "    all_data = combine_files(all_files)\n",
    "    random.shuffle(all_data)\n",
    "    train_size = int(0.75*len(all_data))\n",
    "    train = all_data[:train_size]\n",
    "    test = all_data[train_size:]\n",
    "print(f\"Número de Sentenças no Conjunto de Treinamento: {len(train)}\")\n",
    "print(f\"Número de Sentenças no Conjunto de Teste: {len(test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_sents(data:list)->list:\n",
    "    return list(map(lambda x:[w for w,t in x], data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_store = \"HMM-CV\"\n",
    "os.mkdir(to_store)\n",
    "\n",
    "# Aplicacao de 5-fold CV nas sentenças do conjunto de treinamento\n",
    "kfold = KFold(n_splits=5)\n",
    "train = np.array(train, dtype=object)\n",
    "i = 1\n",
    "for t, tt in kfold.split(train):\n",
    "    to_train = train[t].tolist()\n",
    "    to_val = train[tt].tolist()\n",
    "    unlab_test = retrieve_sents(to_val)\n",
    "    hmm = HiddenMarkovModelTrainer().train_supervised(to_train)\n",
    "    yhmm = hmm.tag_sents(unlab_test)\n",
    "    hmm_file = \"\"\n",
    "    for preds, true in zip(yhmm, to_val):\n",
    "        for j in range(len(preds)):\n",
    "            hmm_file += true[j][0] + \" \" + true[j][1] + \" \" + preds[j][1] + \"\\n\"\n",
    "        hmm_file += \"\\n\"\n",
    "    with open(f\"./{to_store}/predictions_file_{i}\", \"w\") as f:\n",
    "        f.write(hmm_file)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Treina e armazena as predições do modelo no conjunto de teste\n",
    "# unlab_test = retrieve_sents(test)\n",
    "# train = train.tolist()\n",
    "# hmm = HiddenMarkovModelTrainer().train_supervised(train)\n",
    "# yhmm = hmm.tag_sents(unlab_test)\n",
    "\n",
    "# hmm_file = \"\"\n",
    "# for preds, true in zip(yhmm, test):\n",
    "#     for j in range(len(preds)):\n",
    "#         hmm_file += true[j][0] + \" \" + true[j][1] + \" \" + preds[j][1] + \"\\n\"\n",
    "#     hmm_file += \"\\n\"\n",
    "# with open(\"predictions_file_final\", \"w\") as f:\n",
    "#     f.write(hmm_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
